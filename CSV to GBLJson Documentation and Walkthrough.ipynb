{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to GeoBlacklight JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script takes an input CSV of metadata and converts it to a GeoBlacklight JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look in the repo for an example input CSV, and let's get started\n",
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary to translate single-value Dublin Core/GBL fields into GBLJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dict = {\n",
    "    \"Dublin Core:Identifier\":[\"layer_slug_s\",\"dc_identifier_s\"],\n",
    "    \"Dublin Core:Provenance\":[\"dct_provenance_s\"],\n",
    "    \"Dublin Core:Title\":[\"dc_title_s\"],\n",
    "    \"Dublin Core:Date\":[\"solr_year_i\"],\n",
    "    \"GeoBlacklight:Geometry Type\":[\"layer_geom_type_s\"],\n",
    "    \"Dublin Core:Date Issued\":[\"dct_issued_s\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is a dictionary to translate multivalue Dublin Core/GBL fields into GBLJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_dict = {\n",
    "    \"Dublin Core:Spatial Coverage\":[\"dct_spatial_sm\"],\n",
    "    \"Dublin Core:Temporal Coverage\":[\"dct_temporal_sm\"],\n",
    "    \"Dublin Core:Is Part Of\":[\"dct_isPartOf_sm\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement will create a folder to store the jsons if one does not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"json\"):\n",
    "    os.mkdir(\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the CSV with the GBL data. Change the string inside the open statement to match your file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('ArcGIS_Reaccession_20190607 - actualNew.csv', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the CSV into a dictionary and sets the date modified to today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(csvfile)\n",
    "date_modified = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is where the work happens. \n",
    "* Each row within the reader is a dictionary containing one line of the CSV. <br>\n",
    "* A starting dictionary is created that has some pre-populated default values. These can change as needed; feel free to modify them. <br>\n",
    "* Each row is examined for an identifying code. This code separates the records into collections. A folder for each code is created in the json folder so that the jsons can be sorted into their respective collection. <br>\n",
    "* The script then goes through the single and multiple dictionaries that were defined above and writes them into the starting dictionary. <br>\n",
    "* Next, the script looks for the the spatial coverage field and splits the WSEN values into their own variables. A centroid is calculated, and the geometry and centroid fields are populated accordingly. If the spatial coverage field doesn't have all of the necessary values, then the geometry and centroid fields are written to be null. <br>\n",
    "* Finally, the unique identifier is pulled out, the output filename is named according to that unique identifier, and the output json file is written. This happens for every row in the CSV, so each record will be written to its own JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in reader: #each row is a dictionary\n",
    "    code = \"\"\n",
    "    small_dict = {\"geoblacklight_version\":\"1.0\",\"dc_rights_s\":\"Public\",\"layer_modified_dt\":date_modified} #starting dictionary with set values\n",
    "    for key,val in row.items():\n",
    "        if key == \"Code\":\n",
    "            code = val\n",
    "            if not os.path.exists(\"json/\" + val): #makes a new folder for each code\n",
    "                os.mkdir(\"json/\" + val)\n",
    "        if key in single_dict:\n",
    "            for fieldname in single_dict[key]:\n",
    "                small_dict[fieldname] = val\n",
    "        if key in multiple_dict:\n",
    "            for fieldname in multiple_dict[key]:\n",
    "                small_dict[fieldname] = val.split('|') #creates a list with the multiple values\n",
    "        if key == \"Dublin Core:Coverage\":\n",
    "            val = val.split(',')\n",
    "            if len(val) == 4: #takes care of bounding box values and calculates centroid\n",
    "                west = val[0]\n",
    "                south = val[1]\n",
    "                east = val[2]\n",
    "                north = val[3]\n",
    "                centerlat = (float(north)+float(south))/2\n",
    "                centerlong = (float(east)+float(west))/2\n",
    "                small_dict[\"solr_geom\"] = \"ENVELOPE(\"+west+\",\"+east+\",\"+north+\",\"+south+\")\"\n",
    "                small_dict[\"b1g_centroid_ss\"] = str(centerlat) + \",\" + str(centerlong)\n",
    "            else: #if the bounding box doesn't have all coordinates, just write values as null\n",
    "                small_dict[\"solr_geom\"] = \"NULL\"\n",
    "                small_dict[\"b1g_centroid_ss\"] = \"NULL\"\n",
    "    iden = row['Dublin Core:Identifier']\n",
    "    filename = iden + \".json\"\n",
    "    with open(\"json/\"+code+\"/\"+filename, 'w') as jsonfile: #writes to a json with the identifier as the filename\n",
    "        json.dump(small_dict,jsonfile,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
